{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyOU/OwgOYnr+99vSiBk+otf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSQNHrob89Bi","executionInfo":{"status":"ok","timestamp":1694787441103,"user_tz":-120,"elapsed":1014655,"user":{"displayName":"Tomas Slaven","userId":"11900321035202824891"}},"outputId":"e62567ca-36ea-4626-c80c-b560c24c3331"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","=======================================================\n","Arguments:\n","image_dir: /content/drive/MyDrive/DataDMD/Elbow/Images\n","train_csv: /content/drive/MyDrive/DataDMD/Elbow/train.csv\n","validation_csv: /content/drive/MyDrive/DataDMD/Elbow/val.csv\n","test_csv: /content/drive/MyDrive/DataDMD/Elbow/test.csv\n","archfile: /content/drive/MyDrive/DMDmodel/deepmad-R50.txt\n","num_classes: 14\n","output_dir: /content/drive/My Drive/deepmadElbowResults\n","output_file_prefix: dmd\n","output_file_extension: .csv\n","=======================================================\n","\n","Batch size: 32\n","Learning Rate: 0.001\n","Resolution: 64\n","\n","Epoch:  0\n","\n","Overall Accuracy: 15.4331\n","Train Loss: 1.0636\n","F1 Score: 6.6060\n","\n","Validation Overall Accuracy: 0.0000\n","Validation Loss: 2.4919\n","-------------------------------------------------\n","\n","Epoch:  1\n","\n","Overall Accuracy: 12.1531\n","Train Loss: 0.5675\n","F1 Score: 5.7584\n","\n","Validation Overall Accuracy: 0.0000\n","Validation Loss: 1.1782\n","-------------------------------------------------\n","\n","Test Overall Accuracy: 0.0000\n","Test Loss: 0.5483\n","F1 Score: 0.0000\n","-------------------------------------------------\n","Test Overall Accuracy: 0.0000\n","Test Loss: 0.8310\n","F1 Score: 0.8658\n","-------------------------------------------------\n","Batch size: 32\n","Learning Rate: 0.001\n","Resolution: 128\n","\n","Epoch:  0\n","\n","Overall Accuracy: 12.6156\n","Train Loss: 1.0519\n","F1 Score: 6.9240\n","\n","Validation Overall Accuracy: 0.5181\n","Validation Loss: 1.3207\n","-------------------------------------------------\n","\n","Epoch:  1\n","\n","Overall Accuracy: 12.8680\n","Train Loss: 0.3895\n","F1 Score: 4.4896\n","\n","Validation Overall Accuracy: 13.9896\n","Validation Loss: 0.9793\n","-------------------------------------------------\n","\n","Test Overall Accuracy: 15.9763\n","Test Loss: 1.2554\n","F1 Score: 10.4879\n","-------------------------------------------------\n","Test Overall Accuracy: 15.9763\n","Test Loss: 1.2554\n","F1 Score: 10.4879\n","-------------------------------------------------\n"]}],"source":["#Training pipeline for DeepMAD classificaiton model by Tomas Slaven of University Of Cape Town\n","#DeepMAD architecture search derived from  https://github.com/alibaba/lightweight-neural-architecture-search\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from PIL import Image\n","import ast\n","import argparse\n","import os\n","\n","#Import Google Drive folder, assuming the use of google colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Import Google Drive folder, assuming the use of google colab\n","import sys\n","sys.path.append('/content/drive/My Drive/DMDmodel/')\n","from cnnnet import CnnNet\n","\n","# Declare highest_mean_accuracy as a global variable\n","global highest_mean_accuracy\n","global highest_f1_score\n","highest_mean_accuracy = 0.0\n","highest_f1_score = 0.0\n","\n","\n","# Custom dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, image_dir, csv_file, transform=None):\n","        self.image_dir = image_dir\n","        self.data = pd.read_csv(csv_file, encoding=\"utf-8\")\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image_id = self.data.iloc[idx, 1]\n","        image_path = f\"{self.image_dir}/{image_id}\"\n","        try:\n","            image = Image.open(image_path).convert(\"RGB\")\n","            label = torch.tensor(self.data.iloc[idx, 2:], dtype=torch.float32)\n","            if self.transform:\n","                image = self.transform(image)\n","\n","            return image, label\n","\n","        except OSError as e:\n","            print(f\"Error opening image: {image_path}\")\n","            print(f\"Error details: {e}\")\n","            return  None, None\n","\n","# Function to load data\n","def load_data(image_dir, train_csv, validation_csv, test_csv, batch_size, resolution):\n","    transform = transforms.Compose(\n","        [\n","            transforms.Resize((resolution, resolution)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.1898, 0.1898, 0.1898], std=[0.2527, 0.2527, 0.2527]),\n","        ]\n","    )\n","\n","    train_dataset = CustomDataset(image_dir, train_csv, transform)\n","    validation_dataset = CustomDataset(image_dir, validation_csv, transform)\n","    test_dataset = CustomDataset(image_dir, test_csv, transform)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, pin_memory=True)\n","\n","    return train_loader, validation_loader, test_loader\n","\n","\n","# Function to train the model\n","def train_model(\n","    model, criterion, optimizer, train_loader, validation_loader, num_epochs,\n","    device, output_folder_path\n","):\n","    global highest_mean_accuracy\n","    global highest_f1_score\n","    highest_mean_accuracy = 0.0\n","    highest_f1_score = 0.0\n","    model.to(device)\n","    all_epoch_metrics = []\n","    val_epoch_metrics = []\n","    train_df = pd.DataFrame()\n","    val_df = pd.DataFrame()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        total_correct = 0\n","        label_correct = [0] * args.num_classes\n","        label_total = [0] * args.num_classes\n","        TP = [0] * args.num_classes\n","        FP = [0] * args.num_classes\n","        TN = [0] * args.num_classes\n","        FN = [0] * args.num_classes\n","        precision, specificity, sensi, FNR, F1, label_accuracy =  [], [], [], [], [], []\n","        print(\"Epoch: \", epoch)\n","        print(\"\")\n","\n","        for images, labels in train_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * images.size(0)\n","\n","            # Calculate accuracies\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","            total_correct += (predicted_labels == labels).all(dim=1).sum().item()\n","            correct_per_label = (predicted_labels == labels).sum(dim=0).tolist()\n","\n","            for i in range(args.num_classes):\n","                label_correct[i] += correct_per_label[i]\n","                label_total[i] += len(images)\n","\n","                #calc TP and FP\n","                true_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 1)).sum().item()\n","                false_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 0)).sum().item()\n","                true_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 0)).sum().item()\n","                false_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 1)).sum().item()\n","\n","                TP[i] += true_positive\n","                FP[i] += false_positive\n","                TN[i] += true_negative\n","                FN[i] += false_negative\n","\n","        #Calculate Label Specific Metrics\n","        for i in range(args.num_classes):\n","            label_accuracy.append(\n","                (label_correct[i] / label_total[i] if label_total[i] > 0 else 0)*100\n","            )\n","            precision.append((TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0)*100)\n","            sensi.append((TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0)*100)\n","            specificity.append((TN[i] / (TN[i] + FP[i]) if TN[i] + FP[i] > 0 else 0)*100)\n","            FNR.append((FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0)*100)\n","            F1.append( 2 * (precision[i] * sensi[i]) / (precision[i] + sensi[i]) if precision[i] + sensi[i] > 0 else 0)\n","\n","        # Calculate macro-averages and overall training accuracy\n","        train_loss /= len(train_loader.dataset)\n","        overall_accuracy = total_correct / len(train_loader.dataset)\n","        train_accuracy = overall_accuracy * 100  # Multiply by 100 to get percentage\n","\n","        label_accuracy.insert(0, train_accuracy )\n","        precision.insert(0, (sum(precision) / args.num_classes))\n","        sensi.insert(0, (sum(sensi) / args.num_classes))\n","        specificity.insert(0, (sum(specificity) / args.num_classes))\n","        FNR.insert(0, (sum(FNR) / args.num_classes))\n","        F1_score = (sum(F1) / args.num_classes)\n","        F1.insert(0, (sum(F1) / args.num_classes))\n","\n","        # Create a dictionary for training metrics and save to DataFrame\n","        train_metrics_dict = {\n","            \"Epoch\": [epoch] * len(label_names),\n","            \"Type (TRAIN)\": label_names,\n","            \"Mean Accuracy (TRAIN)\": label_accuracy,\n","            \"Precision (TRAIN)\": precision,\n","            \"Sensitivity (TRAIN)\": sensi,\n","            \"Specificity (TRAIN)\": specificity,\n","            \"FNR (TRAIN)\": FNR,\n","            \"F1 Score (TRAIN)\": F1,\n","        }\n","        a = pd.DataFrame(train_metrics_dict)\n","        train_df = pd.concat([train_df, a], axis=0)\n","\n","\n","        print(f\"Overall Accuracy: {train_accuracy:.4f}\")\n","        print(f\"Train Loss: {train_loss:.4f}\")\n","        print(f\"F1 Score: {F1_score:.4f}\")\n","        print(\"\")\n","\n","        # Validate the model and get validation metrics\n","        val_metrics_dict = validate_model(\n","            model, criterion, validation_loader, DEVICE, output_folder_path, epoch\n","        )\n","\n","        b = pd.DataFrame(val_metrics_dict)\n","        val_df = pd.concat([val_df, b], axis=0)\n","\n","\n","    # Concatenate all epoch metrics DataFrames vertically\n","    combined_df = pd.concat([train_df, val_df ], axis=1)\n","\n","    return combined_df\n","\n","# Function to validate the model\n","def validate_model(model, criterion, validation_loader, device, output_folder_path, epoch):\n","    model.eval()\n","    global highest_mean_accuracy\n","    global highest_f1_score\n","\n","\n","    with torch.no_grad():\n","        validation_loss = 0.0\n","        total_correct = 0\n","        label_correct = [0] * args.num_classes\n","        label_total = [0] * args.num_classes\n","        TP = [0] * args.num_classes\n","        FP = [0] * args.num_classes\n","        TN = [0] * args.num_classes\n","        FN = [0] * args.num_classes\n","        precision, specificity, sensi, FNR, F1, label_accuracy =  [], [], [], [], [], []\n","\n","        for images, labels in validation_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            validation_loss += loss.item() * images.size(0)\n","\n","\n","            # Calculate accuracies\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","            total_correct += (predicted_labels == labels).all(dim=1).sum().item()\n","            correct_per_label = (predicted_labels == labels).sum(dim=0).tolist()\n","\n","            for i in range(args.num_classes):\n","                label_correct[i] += correct_per_label[i]\n","                label_total[i] += len(images)\n","\n","                #calc TP and FP\n","                true_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 1)).sum().item()\n","                false_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 0)).sum().item()\n","                true_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 0)).sum().item()\n","                false_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 1)).sum().item()\n","\n","                TP[i] += true_positive\n","                FP[i] += false_positive\n","                TN[i] += true_negative\n","                FN[i] += false_negative\n","\n","        #Calculate Label Specific Metrics\n","        for i in range(args.num_classes):\n","            label_accuracy.append((label_correct[i] / label_total[i] if label_total[i] > 0 else 0)*100)\n","            precision.append((TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0)*100)\n","            sensi.append((TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0)*100)\n","            specificity.append((TN[i] / (TN[i] + FP[i]) if TN[i] + FP[i] > 0 else 0)*100)\n","            FNR.append((FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0)*100)\n","            F1.append( 2 * (precision[i] * sensi[i]) / (precision[i] + sensi[i]) if precision[i] + sensi[i] > 0 else 0)\n","\n","        # Calculate macro-averages and overall validation accuracy\n","        validation_loss /= len(validation_loader.dataset)\n","        overall_accuracy = total_correct / len(validation_loader.dataset)\n","        validation_accuracy = (overall_accuracy * 100)\n","        label_accuracy.insert(0, validation_accuracy )\n","        precision.insert(0, (sum(precision) / args.num_classes))\n","        sensi.insert(0, (sum(sensi) / args.num_classes))\n","        specificity.insert(0, (sum(specificity) / args.num_classes))\n","        FNR.insert(0, (sum(FNR) / args.num_classes))\n","        F1.insert(0, (sum(F1) / args.num_classes))\n","\n","        #Create a dictionary for validation metrics and save to DataFrame\n","        val_metrics_dict = {\n","            \"Epoch\": [epoch] * len(label_names),\n","            \"Type (VAL)\": label_names,\n","            \"Mean Accuracy (VAL)\": label_accuracy,\n","            \"Precision (VAL)\": precision,\n","            \"Sensitivity (VAL)\": sensi,\n","            \"Specificity (VAL)\": specificity,\n","            \"FNR (VAL)\": FNR,\n","            \"F1 Score (VAL)\": F1,\n","        }\n","\n","        mean_accuracy = validation_accuracy\n","        f1_score_mean = F1[0]\n","\n","        # Update the highest mean accuracy and save the model if needed\n","        if ((mean_accuracy > highest_mean_accuracy) or (highest_mean_accuracy == 0.0)):\n","            highest_mean_accuracy = mean_accuracy\n","            model_save_path = os.path.join(output_folder_path, 'model_highest_mean_accuracy.pth')\n","            torch.save(model.state_dict(), model_save_path)\n","\n","        # Update the highest F1 score and save the model if needed\n","        if ((f1_score_mean > highest_f1_score) or (highest_f1_score == 0.0)):\n","            highest_f1_score = f1_score_mean\n","            model_save_path = os.path.join(output_folder_path, 'model_highest_f1_score.pth')\n","            torch.save(model.state_dict(), model_save_path)\n","\n","        # Print label accuracies and overall accuracy\n","        print(f\"Validation Overall Accuracy: {validation_accuracy:.4f}\")\n","        print(f\"Validation Loss: {validation_loss:.4f}\")\n","        print(\"-------------------------------------------------\")\n","        print(\"\")\n","\n","    return val_metrics_dict\n","\n","# Function to test the model\n","def test_model(model, criterion, test_loader, device):\n","    model.eval()\n","    test_loss = 0.0\n","\n","    with torch.no_grad():\n","        total_correct = 0\n","        label_correct = [0] * args.num_classes\n","        label_total = [0] * args.num_classes\n","        TP = [0] * args.num_classes\n","        FP = [0] * args.num_classes\n","        TN = [0] * args.num_classes\n","        FN = [0] * args.num_classes\n","        precision, specificity, sensi, FNR, F1, label_accuracy =  [], [], [], [], [], []\n","\n","\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            test_loss += loss.item() * images.size(0)\n","\n","            # Calculate accuracies\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","            total_correct += (predicted_labels == labels).all(dim=1).sum().item()\n","            correct_per_label = (predicted_labels == labels).sum(dim=0).tolist()\n","\n","            for i in range(args.num_classes):\n","                label_correct[i] += correct_per_label[i]\n","                label_total[i] += len(images)\n","\n","                #calc TP and FP\n","                true_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 1)).sum().item()\n","                false_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 0)).sum().item()\n","                true_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 0)).sum().item()\n","                false_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 1)).sum().item()\n","\n","                TP[i] += true_positive\n","                FP[i] += false_positive\n","                TN[i] += true_negative\n","                FN[i] += false_negative\n","\n","        #Calculate Label Specific Metrics\n","        for i in range(args.num_classes):\n","            label_accuracy.append((label_correct[i] / label_total[i] if label_total[i] > 0 else 0)*100)\n","            precision.append((TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0)*100)\n","            sensi.append((TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0)*100)\n","            specificity.append((TN[i] / (TN[i] + FP[i]) if TN[i] + FP[i] > 0 else 0)*100)\n","            FNR.append((FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0)*100)\n","            F1.append( 2 * (precision[i] * sensi[i]) / (precision[i] + sensi[i]) if precision[i] + sensi[i] > 0 else 0)\n","\n","        # Calculate overall test accuracy and macro averages\n","        overall_accuracy = total_correct / len(test_loader.dataset)\n","        test_loss /= len(test_loader.dataset)\n","        test_accuracy = (overall_accuracy * 100)  # Multiply by 100 to get percentage\n","        label_accuracy.insert(0, test_accuracy )\n","        precision.insert(0, (sum(precision) / args.num_classes))\n","        sensi.insert(0, (sum(sensi) / args.num_classes))\n","        specificity.insert(0, (sum(specificity) / args.num_classes))\n","        FNR.insert(0, (sum(FNR) / args.num_classes))\n","        F1_score = (sum(F1) / args.num_classes)\n","        F1.insert(0, (sum(F1) / args.num_classes))\n","        epoch = 1\n","\n","        #Create a dictionary for test metrics and save to DataFrame\n","        test_metrics_dict = {\n","            \"Epoch\": [epoch] * len(label_names),\n","            \"Type (TEST)\": label_names,\n","            \"Mean Accuracy (TEST)\": label_accuracy,\n","            \"Precision (TEST)\": precision,\n","            \"Sensitivity (TEST)\": sensi,\n","            \"Specificity (TEST)\": specificity,\n","            \"FNR (TEST)\": FNR,\n","            \"F1 Score (TEST)\": F1,\n","        }\n","\n","        # Print label accuracies and overall accuracy\n","        print(f\"Test Overall Accuracy: {test_accuracy:.4f}\")\n","        print(f\"Test Loss: {test_loss:.4f}\")\n","        print(f\"F1 Score: {F1_score:.4f}\")\n","        print(\"-------------------------------------------------\")\n","\n","    return test_metrics_dict\n","\n","\n","# Function to calculate class weights based on a CSV file\n","def calcWeights(csv_path):\n","    train_df = pd.read_csv(csv_path)\n","    columns = train_df.keys()\n","    columns = list(columns)\n","    columns.remove(\"Num\")\n","    columns.remove(\"ID\")\n","    pos_count = []\n","    neg_count = []\n","    pos_weights = []\n","    total = 2380\n","    for column in columns:\n","        pos_count.append(train_df[column].sum())\n","        neg_count.append(total - (train_df[column].sum()))\n","        pos_weights.append((total - (train_df[column].sum())) / total)\n","    return pos_weights\n","\n","\n","if __name__ == \"__main__\":\n","\n","    #initialize arguments for training\n","    args = argparse.Namespace(\n","        image_dir=\"/content/drive/MyDrive/DataDMD/Elbow/Images\",\n","        train_csv=\"/content/drive/MyDrive/DataDMD/Elbow/train.csv\",\n","        validation_csv=\"/content/drive/MyDrive/DataDMD/Elbow/val.csv\",\n","        test_csv=\"/content/drive/MyDrive/DataDMD/Elbow/test.csv\",\n","        archfile = \"/content/drive/MyDrive/DMDmodel/deepmad-R50.txt\",\n","        num_classes=14,\n","        output_dir=\"/content/drive/My Drive/deepmadElbowResults\",\n","        output_file_prefix=\"dmd\",\n","        output_file_extension=\".csv\",\n","        )\n","\n","    print(\"=======================================================\")\n","    print(\"Arguments:\")\n","    for arg, value in vars(args).items():\n","        print(f\"{arg}: {value}\")\n","    print(\"=======================================================\")\n","    print(\"\")\n","\n","    #Initializations\n","    results_df = pd.DataFrame()\n","    label_names = [\n","        \"Overall (Macro-Average)\",\n","        \"Soft tissue swelling\",\n","        \"Joint effusion\",\n","        \"Distal humerus\",\n","        \"supracondylar\",\n","        \"medial epicondyle displaced\",\n","        \"lateral epicondyle displaced\",\n","        \"olecranon\",\n","        \"Elbow dislocation anterior\",\n","        \"Elbow dislocation posterior\",\n","        \"proximal radial\",\n","        \"radial head\",\n","        \"radial head subluxation\",\n","        \"proximal ulnar metaphysis\",\n","        \"normal\",\n","    ]\n","    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    pos_weights = torch.tensor(calcWeights(args.train_csv), device=DEVICE)\n","\n","    # Create the output directory if it doesn't exist\n","    os.makedirs(args.output_dir, exist_ok=True)\n","\n","    #Initial Hyperparameter Grid\n","    hyperparameter_grid = [\n","        {\"bs\": 32, \"lr\": 0.001, \"res\": 64, \"epochs\": 2},\n","        {\"bs\": 32, \"lr\": 0.001, \"res\": 128, \"epochs\": 2},\n","        # {\"bs\": 32, \"lr\": 0.001, \"res\": 64, \"epochs\": 15},\n","        # {\"bs\": 32, \"lr\": 0.001, \"res\": 128, \"epochs\": 15},\n","        # {\"bs\": 64, \"lr\": 0.001, \"res\": 64, \"epochs\": 15},\n","        # {\"bs\": 64, \"lr\": 0.001, \"res\": 128, \"epochs\": 15},\n","        # {\"bs\": 32, \"lr\": 0.002, \"res\": 64, \"epochs\": 15},\n","        # {\"bs\": 32, \"lr\": 0.002, \"res\": 128, \"epochs\": 15},\n","        # {\"bs\": 64, \"lr\": 0.002, \"res\": 64, \"epochs\": 15},\n","        # {\"bs\": 64, \"lr\": 0.002, \"res\": 128, \"epochs\": 15},\n","        # {\"bs\": 32, \"lr\": 0.0015, \"res\": 96, \"epochs\": 15},\n","        # Add more combinations if desired\n","    ]\n","\n","    for hyperparams in hyperparameter_grid:\n","\n","        #Initialize hyperparamters\n","        batch_size = hyperparams[\"bs\"]\n","        learning_rate = hyperparams[\"lr\"]\n","        resolution = hyperparams[\"res\"]\n","        epochs = hyperparams[\"epochs\"]\n","\n","        #initialize output directory\n","        output_df = pd.DataFrame()\n","        folder_name = f\"bs{batch_size}_lr{learning_rate:.5f}_res{resolution}_ep{epochs}\"\n","        output_folder_path = os.path.join(args.output_dir, folder_name)\n","        os.makedirs(output_folder_path, exist_ok=True)\n","        output_file_path = os.path.join(output_folder_path, \"output.csv\")\n","\n","        #Print Current Hyperparameters\n","        print(\"Batch size:\", batch_size)\n","        print(\"Learning Rate:\", learning_rate)\n","        print(\"Resolution:\", resolution)\n","        print(\"\")\n","\n","        # Load data with the current hyperparameter settings\n","        train_loader, validation_loader, test_loader = load_data(\n","            args.image_dir,\n","            args.train_csv,\n","            args.validation_csv,\n","            args.test_csv,\n","            batch_size,\n","            resolution,\n","        )\n","\n","        # Create the model with the current hyperparameter settings\n","        # Load the optimal structure from a file\n","        with open(args.archfile, \"r\") as fin:\n","            content = fin.read()\n","            output_structures = ast.literal_eval(content)\n","\n","        network_arch = output_structures[\"space_arch\"]\n","        best_structures = output_structures[\"best_structures\"]\n","\n","        # Instantiate the classification backbone network\n","        network_id = 0  # Index number. Multiple structures can be output during the search.\n","        out_indices = (4,)  # Output stage\n","        backbone = CnnNet(\n","            structure_info=best_structures[network_id],\n","            out_indices=out_indices,\n","            num_classes=args.num_classes,\n","            classification=True,\n","        )\n","        backbone.fc = nn.Linear(2896, args.num_classes)\n","        model = backbone\n","\n","        # Define loss function and optimizer\n","        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","        # Train the model\n","        train_val_df = train_model(\n","            model,\n","            criterion,\n","            optimizer,\n","            train_loader,\n","            validation_loader,\n","            epochs,\n","            DEVICE,\n","            output_folder_path,\n","        )\n","        del model\n","\n","        # Test the model on best Mean Acc\n","        best_mean_accuracy_model = CnnNet(\n","            structure_info=best_structures[network_id],\n","            out_indices=out_indices,\n","            num_classes=args.num_classes,\n","            classification=True,\n","        )\n","        best_mean_accuracy_model.fc = nn.Linear(2896, args.num_classes)\n","        best_mean_accuracy_model.load_state_dict(torch.load(os.path.join(output_folder_path, 'model_highest_mean_accuracy.pth')))\n","        best_mean_accuracy_model.to(DEVICE)\n","        mean_acc_test_metrics_dict = test_model(\n","            best_mean_accuracy_model, criterion, test_loader, DEVICE\n","        )\n","        del best_mean_accuracy_model\n","\n","\n","        # Test the model on best F1 Macro-Average\n","        best_f1_score_model = CnnNet(\n","            structure_info=best_structures[network_id],\n","            out_indices=out_indices,\n","            num_classes=args.num_classes,\n","            classification=True,\n","        )\n","        best_f1_score_model.fc = nn.Linear(2896, args.num_classes)\n","        best_f1_score_model.load_state_dict(torch.load(os.path.join(output_folder_path, 'model_highest_f1_score.pth')))\n","        best_f1_score_model.to(DEVICE)\n","        macro_F1_test_metrics_dict = test_model(\n","            best_f1_score_model, criterion, test_loader, DEVICE\n","        )\n","        del best_f1_score_model\n","\n","        #accumulate results\n","        mean_acc_test_df = pd.DataFrame(mean_acc_test_metrics_dict)\n","        mean_F1_test_df = pd.DataFrame(macro_F1_test_metrics_dict)\n","        test_df = pd.concat([mean_acc_test_df, mean_F1_test_df ], axis=1)\n","        csv_df = pd.concat([train_val_df, test_df ], axis=1)\n","\n","        #save individual model results\n","        csv_df.to_csv(output_file_path, index=False)\n","\n","        #Find best Mean Accuracy and F1 Score\n","        overall_mean_acc = mean_acc_test_metrics_dict[\"Mean Accuracy (TEST)\"][0]\n","        mac_f1 =  mean_acc_test_metrics_dict[\"F1 Score (TEST)\"][0]\n","        overall_macro_F1 = macro_F1_test_metrics_dict[\"F1 Score (TEST)\"][0]\n","        mac_acc = macro_F1_test_metrics_dict[\"Mean Accuracy (TEST)\"][0]\n","        if mac_acc > overall_mean_acc:\n","            overall_mean_acc = mac_acc\n","\n","        if mac_f1 > overall_macro_F1:\n","            overall_macro_F1 = mac_f1\n","\n","        #Save Best Results to dictionary\n","        results_dict = {\n","        \"hyperparameters\": hyperparams,\n","        \"test_metrics_mean_acc\": overall_mean_acc,\n","        \"test_metrics_macro_F1\": overall_macro_F1\n","        }\n","\n","        #Append dictionary to other results for same hyperparameter search\n","        a_df = pd.DataFrame(results_dict)\n","        results_df = pd.concat([results_df, a_df ], axis=0)\n","\n","\n","\n","    #initilize hyperparameter results file\n","    output_file_name = \"GridSearchResults\"\n","    output_file_path = os.path.join(args.output_dir, output_file_name + \".csv\")\n","\n","    # Create a DataFrame from the hyperparameter search results and save to a CSV file\n","    results_df.to_csv(output_file_path, index=False)\n"]}]}