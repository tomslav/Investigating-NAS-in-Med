{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyNltWjLcTZdsx2Qre3V+WBX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3ABip3e2lAMv","outputId":"e95a49da-8296-4d87-b6c2-024bfb404115","executionInfo":{"status":"error","timestamp":1694790717036,"user_tz":-120,"elapsed":2964047,"user":{"displayName":"Tomas Slaven","userId":"11900321035202824891"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","=======================================================\n","Arguments:\n","image_dir: /content/drive/MyDrive/DataDMD/Elbow/Images\n","train_csv: /content/drive/MyDrive/DataDMD/Elbow/train.csv\n","validation_csv: /content/drive/MyDrive/DataDMD/Elbow/val.csv\n","test_csv: /content/drive/MyDrive/DataDMD/Elbow/test.csv\n","archfile: /content/drive/MyDrive/DMDmodel/R50-like.txt\n","num_classes: 14\n","output_dir: /content/drive/My Drive/zenElbowResults\n","output_file_prefix: zen\n","output_file_extension: .csv\n","=======================================================\n","\n","[0.8974789915966387, 0.7928571428571428, 0.973109243697479, 0.7096638655462185, 0.9701680672268908, 0.9533613445378152, 0.9781512605042016, 0.9949579831932773, 0.9802521008403361, 0.9831932773109243, 0.9941176470588236, 0.992436974789916, 0.988655462184874, 0.4726890756302521]\n","Batch size: 32\n","Learning Rate: 0.001\n","Resolution: 64\n","\n","Epoch:  0\n","\n","Overall Accuracy: 10.0925\n","Train Loss: 1.0834\n","F1 Score: 8.6821\n","\n","Validation Overall Accuracy: 27.9793\n","Validation Loss: 83.1305\n","-------------------------------------------------\n","\n","Epoch:  1\n","\n","Overall Accuracy: 17.3255\n","Train Loss: 0.4900\n","F1 Score: 5.0589\n","\n","Validation Overall Accuracy: 20.2073\n","Validation Loss: 0.7331\n","-------------------------------------------------\n","\n","Test Overall Accuracy: 9.4675\n","Test Loss: 135.4996\n","F1 Score: 1.9565\n","-------------------------------------------------\n","Test Overall Accuracy: 26.0355\n","Test Loss: 0.5604\n","F1 Score: 4.8549\n","-------------------------------------------------\n","Batch size: 32\n","Learning Rate: 0.001\n","Resolution: 128\n","\n","Epoch:  0\n","\n","Overall Accuracy: 10.6392\n","Train Loss: 1.0126\n","F1 Score: 5.6496\n","\n","Validation Overall Accuracy: 17.6166\n","Validation Loss: 0.4358\n","-------------------------------------------------\n","\n","Epoch:  1\n","\n","Overall Accuracy: 9.1253\n","Train Loss: 0.3150\n","F1 Score: 2.6439\n","\n","Validation Overall Accuracy: 15.5440\n","Validation Loss: 0.4997\n","-------------------------------------------------\n","\n","Test Overall Accuracy: 25.4438\n","Test Loss: 0.3704\n","F1 Score: 5.5458\n","-------------------------------------------------\n","Test Overall Accuracy: 25.4438\n","Test Loss: 0.3704\n","F1 Score: 5.5458\n","-------------------------------------------------\n","Batch size: 32\n","Learning Rate: 0.001\n","Resolution: 64\n","\n","Epoch:  0\n","\n","Overall Accuracy: 13.0362\n","Train Loss: 1.1204\n","F1 Score: 8.1238\n","\n","Validation Overall Accuracy: 0.5181\n","Validation Loss: 2.4968\n","-------------------------------------------------\n","\n","Epoch:  1\n","\n","Overall Accuracy: 16.3162\n","Train Loss: 0.5386\n","F1 Score: 5.4869\n","\n","Validation Overall Accuracy: 5.1813\n","Validation Loss: 0.8709\n","-------------------------------------------------\n","\n","Epoch:  2\n","\n","Overall Accuracy: 9.7981\n","Train Loss: 0.4073\n","F1 Score: 3.3154\n","\n","Validation Overall Accuracy: 1.5544\n","Validation Loss: 0.6919\n","-------------------------------------------------\n","\n","Epoch:  3\n","\n","Overall Accuracy: 13.6669\n","Train Loss: 0.3151\n","F1 Score: 3.6162\n","\n","Validation Overall Accuracy: 1.5544\n","Validation Loss: 0.5011\n","-------------------------------------------------\n","\n","Epoch:  4\n","\n","Overall Accuracy: 12.2372\n","Train Loss: 0.3222\n","F1 Score: 3.1927\n","\n","Validation Overall Accuracy: 2.0725\n","Validation Loss: 1.7110\n","-------------------------------------------------\n","\n","Epoch:  5\n","\n","Overall Accuracy: 13.8352\n","Train Loss: 0.2705\n","F1 Score: 3.8752\n","\n","Validation Overall Accuracy: 4.6632\n","Validation Loss: 0.6875\n","-------------------------------------------------\n","\n","Epoch:  6\n","\n","Overall Accuracy: 11.1859\n","Train Loss: 0.2839\n","F1 Score: 3.6759\n","\n","Validation Overall Accuracy: 2.5907\n","Validation Loss: 0.9329\n","-------------------------------------------------\n","\n","Epoch:  7\n","\n","Overall Accuracy: 15.0967\n","Train Loss: 0.2977\n","F1 Score: 3.6592\n","\n","Validation Overall Accuracy: 9.8446\n","Validation Loss: 2.3518\n","-------------------------------------------------\n","\n","Epoch:  8\n","\n","Overall Accuracy: 13.4146\n","Train Loss: 0.2454\n","F1 Score: 3.5481\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1c10311886cf>\u001b[0m in \u001b[0;36m<cell line: 405>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         train_val_df = train_model(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-1c10311886cf>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, validation_loader, num_epochs, device, output_folder_path)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Validate the model and get validation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         val_metrics_dict = validate_model(\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         )\n","\u001b[0;32m<ipython-input-1-1c10311886cf>\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, criterion, validation_loader, device, output_folder_path, epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFNR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-1c10311886cf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#Training pipeline for ZenNAS classificaiton model by Tomas Slaven of University Of Cape Town\n","#ZenNAS architecture search derived from https://github.com/idstcv/ZenNAS\n","\n","#Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from PIL import Image\n","import ast\n","import argparse\n","import os\n","\n","#Import Google Drive folder, assuming the use of google colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Import Google Drive folder, assuming the use of google colab\n","import sys\n","sys.path.append('/content/drive/My Drive/DMDmodel/')\n","from cnnnet import CnnNet\n","\n","# Declare highest_mean_accuracy as a global variable\n","global highest_mean_accuracy\n","global highest_f1_score\n","highest_mean_accuracy = 0.0\n","highest_f1_score = 0.0\n","\n","\n","# Custom dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, image_dir, csv_file, transform=None):\n","        self.image_dir = image_dir\n","        self.data = pd.read_csv(csv_file, encoding=\"utf-8\")\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image_id = self.data.iloc[idx, 1]\n","        image_path = f\"{self.image_dir}/{image_id}\"\n","        try:\n","            image = Image.open(image_path).convert(\"RGB\")\n","            label = torch.tensor(self.data.iloc[idx, 2:], dtype=torch.float32)\n","            if self.transform:\n","                image = self.transform(image)\n","\n","            return image, label\n","\n","        except OSError as e:\n","            print(f\"Error opening image: {image_path}\")\n","            print(f\"Error details: {e}\")\n","            return  None, None\n","\n","# Function to load data\n","def load_data(image_dir, train_csv, validation_csv, test_csv, batch_size, resolution):\n","    transform = transforms.Compose(\n","        [\n","            transforms.Resize((resolution, resolution)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.1898, 0.1898, 0.1898], std=[0.2527, 0.2527, 0.2527]),\n","        ]\n","    )\n","\n","    train_dataset = CustomDataset(image_dir, train_csv, transform)\n","    validation_dataset = CustomDataset(image_dir, validation_csv, transform)\n","    test_dataset = CustomDataset(image_dir, test_csv, transform)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, pin_memory=True)\n","\n","    return train_loader, validation_loader, test_loader\n","\n","\n","# Function to train the model\n","def train_model(\n","    model, criterion, optimizer, train_loader, validation_loader, num_epochs,\n","    device, output_folder_path\n","):\n","    global highest_mean_accuracy\n","    global highest_f1_score\n","    highest_mean_accuracy = 0.0\n","    highest_f1_score = 0.0\n","    model.to(device)\n","    all_epoch_metrics = []\n","    val_epoch_metrics = []\n","    train_df = pd.DataFrame()\n","    val_df = pd.DataFrame()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        total_correct = 0\n","        label_correct = [0] * args.num_classes\n","        label_total = [0] * args.num_classes\n","        TP = [0] * args.num_classes\n","        FP = [0] * args.num_classes\n","        TN = [0] * args.num_classes\n","        FN = [0] * args.num_classes\n","        precision, specificity, sensi, FNR, F1, label_accuracy =  [], [], [], [], [], []\n","        print(\"Epoch: \", epoch)\n","        print(\"\")\n","\n","        for images, labels in train_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * images.size(0)\n","\n","            # Calculate accuracies\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","            total_correct += (predicted_labels == labels).all(dim=1).sum().item()\n","            correct_per_label = (predicted_labels == labels).sum(dim=0).tolist()\n","\n","            for i in range(args.num_classes):\n","                label_correct[i] += correct_per_label[i]\n","                label_total[i] += len(images)\n","\n","                #calc TP and FP\n","                true_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 1)).sum().item()\n","                false_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 0)).sum().item()\n","                true_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 0)).sum().item()\n","                false_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 1)).sum().item()\n","\n","                TP[i] += true_positive\n","                FP[i] += false_positive\n","                TN[i] += true_negative\n","                FN[i] += false_negative\n","\n","        #Calculate Label Specific Metrics\n","        for i in range(args.num_classes):\n","            label_accuracy.append(\n","                (label_correct[i] / label_total[i] if label_total[i] > 0 else 0)*100\n","            )\n","            precision.append((TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0)*100)\n","            sensi.append((TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0)*100)\n","            specificity.append((TN[i] / (TN[i] + FP[i]) if TN[i] + FP[i] > 0 else 0)*100)\n","            FNR.append((FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0)*100)\n","            F1.append( 2 * (precision[i] * sensi[i]) / (precision[i] + sensi[i]) if precision[i] + sensi[i] > 0 else 0)\n","\n","        # Calculate macro-averages and overall training accuracy\n","        train_loss /= len(train_loader.dataset)\n","        overall_accuracy = total_correct / len(train_loader.dataset)\n","        train_accuracy = overall_accuracy * 100  # Multiply by 100 to get percentage\n","\n","        label_accuracy.insert(0, train_accuracy )\n","        precision.insert(0, (sum(precision) / args.num_classes))\n","        sensi.insert(0, (sum(sensi) / args.num_classes))\n","        specificity.insert(0, (sum(specificity) / args.num_classes))\n","        FNR.insert(0, (sum(FNR) / args.num_classes))\n","        F1_score = (sum(F1) / args.num_classes)\n","        F1.insert(0, (sum(F1) / args.num_classes))\n","\n","        # Create a dictionary for training metrics and save to DataFrame\n","        train_metrics_dict = {\n","            \"Epoch\": [epoch] * len(label_names),\n","            \"Type (TRAIN)\": label_names,\n","            \"Mean Accuracy (TRAIN)\": label_accuracy,\n","            \"Precision (TRAIN)\": precision,\n","            \"Sensitivity (TRAIN)\": sensi,\n","            \"Specificity (TRAIN)\": specificity,\n","            \"FNR (TRAIN)\": FNR,\n","            \"F1 Score (TRAIN)\": F1,\n","        }\n","        a = pd.DataFrame(train_metrics_dict)\n","        train_df = pd.concat([train_df, a], axis=0)\n","\n","\n","        print(f\"Overall Accuracy: {train_accuracy:.4f}\")\n","        print(f\"Train Loss: {train_loss:.4f}\")\n","        print(f\"F1 Score: {F1_score:.4f}\")\n","        print(\"\")\n","\n","        # Validate the model and get validation metrics\n","        val_metrics_dict = validate_model(\n","            model, criterion, validation_loader, DEVICE, output_folder_path, epoch\n","        )\n","\n","        b = pd.DataFrame(val_metrics_dict)\n","        val_df = pd.concat([val_df, b], axis=0)\n","\n","\n","    # Concatenate all epoch metrics DataFrames vertically\n","    combined_df = pd.concat([train_df, val_df ], axis=1)\n","\n","    return combined_df\n","\n","# Function to validate the model\n","def validate_model(model, criterion, validation_loader, device, output_folder_path, epoch):\n","    model.eval()\n","    global highest_mean_accuracy\n","    global highest_f1_score\n","\n","\n","    with torch.no_grad():\n","        validation_loss = 0.0\n","        total_correct = 0\n","        label_correct = [0] * args.num_classes\n","        label_total = [0] * args.num_classes\n","        TP = [0] * args.num_classes\n","        FP = [0] * args.num_classes\n","        TN = [0] * args.num_classes\n","        FN = [0] * args.num_classes\n","        precision, specificity, sensi, FNR, F1, label_accuracy =  [], [], [], [], [], []\n","\n","        for images, labels in validation_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            validation_loss += loss.item() * images.size(0)\n","\n","\n","            # Calculate accuracies\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","            total_correct += (predicted_labels == labels).all(dim=1).sum().item()\n","            correct_per_label = (predicted_labels == labels).sum(dim=0).tolist()\n","\n","            for i in range(args.num_classes):\n","                label_correct[i] += correct_per_label[i]\n","                label_total[i] += len(images)\n","\n","                #calc TP and FP\n","                true_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 1)).sum().item()\n","                false_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 0)).sum().item()\n","                true_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 0)).sum().item()\n","                false_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 1)).sum().item()\n","\n","                TP[i] += true_positive\n","                FP[i] += false_positive\n","                TN[i] += true_negative\n","                FN[i] += false_negative\n","\n","        #Calculate Label Specific Metrics\n","        for i in range(args.num_classes):\n","            label_accuracy.append((label_correct[i] / label_total[i] if label_total[i] > 0 else 0)*100)\n","            precision.append((TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0)*100)\n","            sensi.append((TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0)*100)\n","            specificity.append((TN[i] / (TN[i] + FP[i]) if TN[i] + FP[i] > 0 else 0)*100)\n","            FNR.append((FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0)*100)\n","            F1.append( 2 * (precision[i] * sensi[i]) / (precision[i] + sensi[i]) if precision[i] + sensi[i] > 0 else 0)\n","\n","        # Calculate macro-averages and overall validation accuracy\n","        validation_loss /= len(validation_loader.dataset)\n","        overall_accuracy = total_correct / len(validation_loader.dataset)\n","        validation_accuracy = (overall_accuracy * 100)\n","        label_accuracy.insert(0, validation_accuracy )\n","        precision.insert(0, (sum(precision) / args.num_classes))\n","        sensi.insert(0, (sum(sensi) / args.num_classes))\n","        specificity.insert(0, (sum(specificity) / args.num_classes))\n","        FNR.insert(0, (sum(FNR) / args.num_classes))\n","        F1.insert(0, (sum(F1) / args.num_classes))\n","\n","        #Create a dictionary for validation metrics and save to DataFrame\n","        val_metrics_dict = {\n","            \"Epoch\": [epoch] * len(label_names),\n","            \"Type (VAL)\": label_names,\n","            \"Mean Accuracy (VAL)\": label_accuracy,\n","            \"Precision (VAL)\": precision,\n","            \"Sensitivity (VAL)\": sensi,\n","            \"Specificity (VAL)\": specificity,\n","            \"FNR (VAL)\": FNR,\n","            \"F1 Score (VAL)\": F1,\n","        }\n","\n","        mean_accuracy = validation_accuracy\n","        f1_score_mean = F1[0]\n","\n","        # Update the highest mean accuracy and save the model if needed\n","        if ((mean_accuracy > highest_mean_accuracy) or (highest_mean_accuracy == 0.0)):\n","            highest_mean_accuracy = mean_accuracy\n","            model_save_path = os.path.join(output_folder_path, 'model_highest_mean_accuracy.pth')\n","            torch.save(model.state_dict(), model_save_path)\n","\n","        # Update the highest F1 score and save the model if needed\n","        if ((f1_score_mean > highest_f1_score) or (highest_f1_score == 0.0)):\n","            highest_f1_score = f1_score_mean\n","            model_save_path = os.path.join(output_folder_path, 'model_highest_f1_score.pth')\n","            torch.save(model.state_dict(), model_save_path)\n","\n","        # Print label accuracies and overall accuracy\n","        print(f\"Validation Overall Accuracy: {validation_accuracy:.4f}\")\n","        print(f\"Validation Loss: {validation_loss:.4f}\")\n","        print(\"-------------------------------------------------\")\n","        print(\"\")\n","\n","    return val_metrics_dict\n","\n","# Function to test the model\n","def test_model(model, criterion, test_loader, device):\n","    model.eval()\n","    test_loss = 0.0\n","\n","    with torch.no_grad():\n","        total_correct = 0\n","        label_correct = [0] * args.num_classes\n","        label_total = [0] * args.num_classes\n","        TP = [0] * args.num_classes\n","        FP = [0] * args.num_classes\n","        TN = [0] * args.num_classes\n","        FN = [0] * args.num_classes\n","        precision, specificity, sensi, FNR, F1, label_accuracy =  [], [], [], [], [], []\n","\n","\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            test_loss += loss.item() * images.size(0)\n","\n","            # Calculate accuracies\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","            total_correct += (predicted_labels == labels).all(dim=1).sum().item()\n","            correct_per_label = (predicted_labels == labels).sum(dim=0).tolist()\n","\n","            for i in range(args.num_classes):\n","                label_correct[i] += correct_per_label[i]\n","                label_total[i] += len(images)\n","\n","                #calc TP and FP\n","                true_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 1)).sum().item()\n","                false_positive = ((predicted_labels[:, i] == 1) & (labels[:, i] == 0)).sum().item()\n","                true_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 0)).sum().item()\n","                false_negative = ((predicted_labels[:, i] == 0) & (labels[:, i] == 1)).sum().item()\n","\n","                TP[i] += true_positive\n","                FP[i] += false_positive\n","                TN[i] += true_negative\n","                FN[i] += false_negative\n","\n","        #Calculate Label Specific Metrics\n","        for i in range(args.num_classes):\n","            label_accuracy.append((label_correct[i] / label_total[i] if label_total[i] > 0 else 0)*100)\n","            precision.append((TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0)*100)\n","            sensi.append((TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0)*100)\n","            specificity.append((TN[i] / (TN[i] + FP[i]) if TN[i] + FP[i] > 0 else 0)*100)\n","            FNR.append((FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0)*100)\n","            F1.append( 2 * (precision[i] * sensi[i]) / (precision[i] + sensi[i]) if precision[i] + sensi[i] > 0 else 0)\n","\n","        # Calculate overall test accuracy and macro averages\n","        overall_accuracy = total_correct / len(test_loader.dataset)\n","        test_loss /= len(test_loader.dataset)\n","        test_accuracy = (overall_accuracy * 100)  # Multiply by 100 to get percentage\n","        label_accuracy.insert(0, test_accuracy )\n","        precision.insert(0, (sum(precision) / args.num_classes))\n","        sensi.insert(0, (sum(sensi) / args.num_classes))\n","        specificity.insert(0, (sum(specificity) / args.num_classes))\n","        FNR.insert(0, (sum(FNR) / args.num_classes))\n","        F1_score = (sum(F1) / args.num_classes)\n","        F1.insert(0, (sum(F1) / args.num_classes))\n","        epoch = 1\n","\n","        #Create a dictionary for test metrics and save to DataFrame\n","        test_metrics_dict = {\n","            \"Epoch\": [epoch] * len(label_names),\n","            \"Type (TEST)\": label_names,\n","            \"Mean Accuracy (TEST)\": label_accuracy,\n","            \"Precision (TEST)\": precision,\n","            \"Sensitivity (TEST)\": sensi,\n","            \"Specificity (TEST)\": specificity,\n","            \"FNR (TEST)\": FNR,\n","            \"F1 Score (TEST)\": F1,\n","        }\n","\n","        # Print label accuracies and overall accuracy\n","        print(f\"Test Overall Accuracy: {test_accuracy:.4f}\")\n","        print(f\"Test Loss: {test_loss:.4f}\")\n","        print(f\"F1 Score: {F1_score:.4f}\")\n","        print(\"-------------------------------------------------\")\n","\n","    return test_metrics_dict\n","\n","\n","# Function to calculate class weights based on a CSV file\n","def calcWeights(csv_path):\n","    train_df = pd.read_csv(csv_path)\n","    columns = train_df.keys()\n","    columns = list(columns)\n","    columns.remove(\"Num\")\n","    columns.remove(\"ID\")\n","    pos_count = []\n","    neg_count = []\n","    pos_weights = []\n","    total = 2380\n","    for column in columns:\n","        pos_count.append(train_df[column].sum())\n","        neg_count.append(total - (train_df[column].sum()))\n","        pos_weights.append((total - (train_df[column].sum())) / total)\n","    return pos_weights\n","\n","\n","if __name__ == \"__main__\":\n","\n","    #initialize arguments for training\n","    args = argparse.Namespace(\n","        image_dir=\"/content/drive/MyDrive/DataDMD/Elbow/Images\",\n","        train_csv=\"/content/drive/MyDrive/DataDMD/Elbow/train.csv\",\n","        validation_csv=\"/content/drive/MyDrive/DataDMD/Elbow/val.csv\",\n","        test_csv=\"/content/drive/MyDrive/DataDMD/Elbow/test.csv\",\n","        archfile = \"/content/drive/MyDrive/DMDmodel/R50-like.txt\",\n","        num_classes=14,\n","        output_dir=\"/content/drive/My Drive/zenElbowResults\",\n","        output_file_prefix=\"zen\",\n","        output_file_extension=\".csv\",\n","        )\n","\n","    print(\"=======================================================\")\n","    print(\"Arguments:\")\n","    for arg, value in vars(args).items():\n","        print(f\"{arg}: {value}\")\n","    print(\"=======================================================\")\n","    print(\"\")\n","\n","    #Initializations\n","    results_df = pd.DataFrame()\n","    label_names = [\n","        \"Overall (Macro-Average)\",\n","        \"Soft tissue swelling\",\n","        \"Joint effusion\",\n","        \"Distal humerus\",\n","        \"supracondylar\",\n","        \"medial epicondyle displaced\",\n","        \"lateral epicondyle displaced\",\n","        \"olecranon\",\n","        \"Elbow dislocation anterior\",\n","        \"Elbow dislocation posterior\",\n","        \"proximal radial\",\n","        \"radial head\",\n","        \"radial head subluxation\",\n","        \"proximal ulnar metaphysis\",\n","        \"normal\",\n","    ]\n","    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    pos_weights = torch.tensor(calcWeights(args.train_csv), device=DEVICE)\n","\n","    # Create the output directory if it doesn't exist\n","    os.makedirs(args.output_dir, exist_ok=True)\n","\n","    #Initial Hyperparameter Grid\n","    hyperparameter_grid = [\n","        {\"bs\": 32, \"lr\": 0.001, \"res\": 64, \"epochs\": 2},\n","        {\"bs\": 32, \"lr\": 0.001, \"res\": 128, \"epochs\": 2},\n","        {\"bs\": 32, \"lr\": 0.001, \"res\": 64, \"epochs\": 15},\n","        {\"bs\": 32, \"lr\": 0.001, \"res\": 128, \"epochs\": 15},\n","        {\"bs\": 64, \"lr\": 0.001, \"res\": 64, \"epochs\": 15},\n","        {\"bs\": 64, \"lr\": 0.001, \"res\": 128, \"epochs\": 15},\n","        {\"bs\": 32, \"lr\": 0.002, \"res\": 64, \"epochs\": 15},\n","        {\"bs\": 32, \"lr\": 0.002, \"res\": 128, \"epochs\": 15},\n","        {\"bs\": 64, \"lr\": 0.002, \"res\": 64, \"epochs\": 15},\n","        {\"bs\": 64, \"lr\": 0.002, \"res\": 128, \"epochs\": 15},\n","        {\"bs\": 32, \"lr\": 0.0015, \"res\": 96, \"epochs\": 15},\n","        # Add more combinations if desired\n","    ]\n","\n","    for hyperparams in hyperparameter_grid:\n","\n","        #Initialize hyperparamters\n","        batch_size = hyperparams[\"bs\"]\n","        learning_rate = hyperparams[\"lr\"]\n","        resolution = hyperparams[\"res\"]\n","        epochs = hyperparams[\"epochs\"]\n","\n","        #initialize output directory\n","        output_df = pd.DataFrame()\n","        folder_name = f\"bs{batch_size}_lr{learning_rate:.5f}_res{resolution}_ep{epochs}\"\n","        output_folder_path = os.path.join(args.output_dir, folder_name)\n","        os.makedirs(output_folder_path, exist_ok=True)\n","        output_file_path = os.path.join(output_folder_path, \"output.csv\")\n","\n","        #Print Current Hyperparameters\n","        print(\"Batch size:\", batch_size)\n","        print(\"Learning Rate:\", learning_rate)\n","        print(\"Resolution:\", resolution)\n","        print(\"\")\n","\n","        # Load data with the current hyperparameter settings\n","        train_loader, validation_loader, test_loader = load_data(\n","            args.image_dir,\n","            args.train_csv,\n","            args.validation_csv,\n","            args.test_csv,\n","            batch_size,\n","            resolution,\n","        )\n","\n","        # Create the model with the current hyperparameter settings\n","        # Load the optimal structure from a file\n","        with open(args.archfile, \"r\") as fin:\n","            content = fin.read()\n","            output_structures = ast.literal_eval(content)\n","\n","        network_arch = output_structures[\"space_arch\"]\n","        best_structures = output_structures[\"best_structures\"]\n","\n","        # Instantiate the classification backbone network\n","        network_id = 0  # Index number. Multiple structures can be output during the search.\n","        out_indices = (4,)  # Output stage\n","        backbone = CnnNet(\n","            structure_info=best_structures[network_id],\n","            out_indices=out_indices,\n","            num_classes=args.num_classes,\n","            classification=True,\n","        )\n","        backbone.fc = nn.Linear(2896, args.num_classes)\n","        model = backbone\n","\n","        # Define loss function and optimizer\n","        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","        # Train the model\n","        train_val_df = train_model(\n","            model,\n","            criterion,\n","            optimizer,\n","            train_loader,\n","            validation_loader,\n","            epochs,\n","            DEVICE,\n","            output_folder_path,\n","        )\n","        del model\n","\n","        # Test the model on best Mean Acc\n","        best_mean_accuracy_model = CnnNet(\n","            structure_info=best_structures[network_id],\n","            out_indices=out_indices,\n","            num_classes=args.num_classes,\n","            classification=True,\n","        )\n","        best_mean_accuracy_model.fc = nn.Linear(2896, args.num_classes)\n","        best_mean_accuracy_model.load_state_dict(torch.load(os.path.join(output_folder_path, 'model_highest_mean_accuracy.pth')))\n","        best_mean_accuracy_model.to(DEVICE)\n","        mean_acc_test_metrics_dict = test_model(\n","            best_mean_accuracy_model, criterion, test_loader, DEVICE\n","        )\n","        del best_mean_accuracy_model\n","\n","\n","        # Test the model on best F1 Macro-Average\n","        best_f1_score_model = CnnNet(\n","            structure_info=best_structures[network_id],\n","            out_indices=out_indices,\n","            num_classes=args.num_classes,\n","            classification=True,\n","        )\n","        best_f1_score_model.fc = nn.Linear(2896, args.num_classes)\n","        best_f1_score_model.load_state_dict(torch.load(os.path.join(output_folder_path, 'model_highest_f1_score.pth')))\n","        best_f1_score_model.to(DEVICE)\n","        macro_F1_test_metrics_dict = test_model(\n","            best_f1_score_model, criterion, test_loader, DEVICE\n","        )\n","        del best_f1_score_model\n","\n","        #accumulate results\n","        mean_acc_test_df = pd.DataFrame(mean_acc_test_metrics_dict)\n","        mean_F1_test_df = pd.DataFrame(macro_F1_test_metrics_dict)\n","        test_df = pd.concat([mean_acc_test_df, mean_F1_test_df ], axis=1)\n","        csv_df = pd.concat([train_val_df, test_df ], axis=1)\n","\n","        #save individual model results\n","        csv_df.to_csv(output_file_path, index=False)\n","\n","        #Find best Mean Accuracy and F1 Score\n","        overall_mean_acc = mean_acc_test_metrics_dict[\"Mean Accuracy (TEST)\"][0]\n","        mac_f1 =  mean_acc_test_metrics_dict[\"F1 Score (TEST)\"][0]\n","        overall_macro_F1 = macro_F1_test_metrics_dict[\"F1 Score (TEST)\"][0]\n","        mac_acc = macro_F1_test_metrics_dict[\"Mean Accuracy (TEST)\"][0]\n","        if mac_acc > overall_mean_acc:\n","            overall_mean_acc = mac_acc\n","\n","        if mac_f1 > overall_macro_F1:\n","            overall_macro_F1 = mac_f1\n","\n","        #Save Best Results to dictionary\n","        results_dict = {\n","        \"hyperparameters\": hyperparams,\n","        \"test_metrics_mean_acc\": overall_mean_acc,\n","        \"test_metrics_macro_F1\": overall_macro_F1\n","        }\n","\n","        #Append dictionary to other results for same hyperparameter search\n","        a_df = pd.DataFrame(results_dict)\n","        results_df = pd.concat([results_df, a_df ], axis=0)\n","\n","\n","\n","    #initilize hyperparameter results file\n","    output_file_name = \"GridSearchResults\"\n","    output_file_path = os.path.join(args.output_dir, output_file_name + \".csv\")\n","\n","    # Create a DataFrame from the hyperparameter search results and save to a CSV file\n","    results_df.to_csv(output_file_path, index=False)\n"]}]}